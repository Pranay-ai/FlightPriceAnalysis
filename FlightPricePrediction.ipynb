{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d94ad3",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyspark.sql.functions import mean,col,size,split,when,concat_ws,collect_list, array_distinct,udf,to_timestamp,round, hour, minute,expr\n",
    "from pyspark.sql.types import StringType,IntegerType,TimestampType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7d7f6e",
   "metadata": {},
   "source": [
    "# Importing CSV File From Google Bucket into Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcf309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PredicitiveFlightDataAnalysis\").getOrCreate()\n",
    "df=spark.read.csv(\"gs://flight-data-bucket-551/itineraries_random_2M.csv\",header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe0c4c",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ee63c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filling The NA Values with Mean\n",
    "def fillna_mean(df, include=set()): \n",
    "    means = df.agg(*(\n",
    "        mean(x).alias(x) for x in df.columns if x in include\n",
    "    ))\n",
    "    return df.fillna(means.first().asDict())\n",
    "df = fillna_mean(df, ['totalTravelDistance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5995e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering NULL value Columns\n",
    "df = df.filter(col('travelDuration').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef58edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['segmentsEquipmentDescription', 'segmentsAirlineCode', 'segmentsCabinCode',\n",
    "                   'segmentsDistance', 'isRefundable', 'legId', 'fareBasisCode',\n",
    "                   'segmentsDepartureTimeEpochSeconds', 'segmentsDepartureTimeRaw',\n",
    "                   'segmentsArrivalAirportCode', 'segmentsDepartureAirportCode',\n",
    "                   'segmentsDurationInSeconds','segmentsArrivalTimeEpochSeconds','segmentsArrivalTimeRaw']\n",
    "\n",
    "# Select columns that are not in the list of columns to drop\n",
    "df = df.select([col(column) for column in df.columns if column not in columns_to_drop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "283eb189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- searchDate: timestamp (nullable = true)\n",
      " |-- flightDate: timestamp (nullable = true)\n",
      " |-- startingAirport: string (nullable = true)\n",
      " |-- destinationAirport: string (nullable = true)\n",
      " |-- travelDuration: string (nullable = true)\n",
      " |-- elapsedDays: integer (nullable = true)\n",
      " |-- isBasicEconomy: boolean (nullable = true)\n",
      " |-- isNonStop: boolean (nullable = true)\n",
      " |-- baseFare: double (nullable = true)\n",
      " |-- totalFare: double (nullable = true)\n",
      " |-- seatsRemaining: integer (nullable = true)\n",
      " |-- totalTravelDistance: integer (nullable = true)\n",
      " |-- segmentsAirlineName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3404548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new Column Number of Stops with Segment Airline Name as Input\n",
    "column_to_split = 'segmentsAirlineName'\n",
    "\n",
    "delimiter = '\\|\\|'\n",
    "\n",
    "df = df.withColumn('numberOfStops', size(split(col(column_to_split), delimiter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "716ae644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_airline_names(airline_names):\n",
    "    if len(set(airline_names)) == 1:\n",
    "        return airline_names[0]\n",
    "    else:\n",
    "        return \"||\".join(airline_names)\n",
    "\n",
    "# Register the UDF with PySpark\n",
    "process_airline_names_udf = udf(process_airline_names, StringType())\n",
    "\n",
    "# Apply the UDF to the 'segmentsAirlineName' column\n",
    "df = df.withColumn(\"segmentsAirlineName\", process_airline_names_udf(split(col(\"segmentsAirlineName\"), '\\|\\|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "476ba116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Time from Format \"P4H5M\" to TimeStrap\n",
    "def convert_duration(duration):\n",
    "    hours_match = re.search(r'(\\d+)H', duration)\n",
    "    minutes_match = re.search(r'(\\d+)M', duration)\n",
    "    \n",
    "    if hours_match and minutes_match:\n",
    "        hours = int(hours_match.group(1))\n",
    "        minutes = int(minutes_match.group(1))\n",
    "        return datetime.strptime(f\"{hours}:{minutes}\", '%H:%M').time()\n",
    "    else:\n",
    "        return None  # Handle cases where the pattern is not found\n",
    "convert_duration_udf = udf(convert_duration, StringType())\n",
    "df = df.withColumn(\"travelDuration\", convert_duration_udf(\"travelDuration\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "940dc7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|travelDurationMinute|travelDurationHour|\n",
      "+--------------------+------------------+\n",
      "|19                  |4                 |\n",
      "|10                  |8                 |\n",
      "|54                  |11                |\n",
      "|20                  |1                 |\n",
      "|41                  |6                 |\n",
      "|6                   |2                 |\n",
      "|28                  |7                 |\n",
      "|30                  |3                 |\n",
      "|20                  |3                 |\n",
      "|51                  |1                 |\n",
      "|26                  |11                |\n",
      "|8                   |5                 |\n",
      "|20                  |6                 |\n",
      "|55                  |5                 |\n",
      "|47                  |9                 |\n",
      "|29                  |8                 |\n",
      "|49                  |8                 |\n",
      "|43                  |8                 |\n",
      "|16                  |8                 |\n",
      "|55                  |7                 |\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extract hours and minutes using regular expressions\n",
    "df = df.withColumn(\"travelDurationHour\",\n",
    "                   expr(\"CAST(regexp_extract(travelDuration, '([0-9]+) hours', 1) AS INT)\"))\n",
    "df = df.withColumn(\"travelDurationMinute\",\n",
    "                   expr(\"CAST(regexp_extract(travelDuration, '([0-9]+) minutes', 1) AS INT)\"))\n",
    "df.select('travelDurationMinute','travelDurationHour').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a679205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['searchDate', 'flightDate', 'startingAirport', 'destinationAirport', 'travelDuration','baseFare']\n",
    "\n",
    "# Select columns that are not in the list of columns to drop\n",
    "df = df.select([col(column) for column in df.columns if column not in columns_to_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19af0dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- elapsedDays: integer (nullable = true)\n",
      " |-- isBasicEconomy: boolean (nullable = true)\n",
      " |-- isNonStop: boolean (nullable = true)\n",
      " |-- totalFare: double (nullable = true)\n",
      " |-- seatsRemaining: integer (nullable = true)\n",
      " |-- totalTravelDistance: integer (nullable = true)\n",
      " |-- segmentsAirlineName: string (nullable = true)\n",
      " |-- numberOfStops: integer (nullable = false)\n",
      " |-- travelDurationHour: integer (nullable = true)\n",
      " |-- travelDurationMinute: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0a8f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Applying Label Encoding to the feature segmentAirlineName\n",
    "columns_to_encode = ['segmentsAirlineName']\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_encoded\").fit(df) for col in columns_to_encode]\n",
    "for indexer in indexers:\n",
    "    df = indexer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd815b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|segmentsAirlineName_encoded|\n",
      "+---------------------------+\n",
      "|                        1.0|\n",
      "|                        1.0|\n",
      "|                        1.0|\n",
      "|                        5.0|\n",
      "|                        1.0|\n",
      "|                        2.0|\n",
      "|                        2.0|\n",
      "|                        2.0|\n",
      "|                        0.0|\n",
      "|                        0.0|\n",
      "|                        7.0|\n",
      "|                        0.0|\n",
      "|                        7.0|\n",
      "|                        1.0|\n",
      "|                        6.0|\n",
      "|                        0.0|\n",
      "|                        1.0|\n",
      "|                        0.0|\n",
      "|                        4.0|\n",
      "|                        5.0|\n",
      "+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('segmentsAirlineName_encoded').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e66c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn(\"segmentsAirlineName_encoded\", round(df[\"segmentsAirlineName_encoded\"]).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa6bf1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that are not in the list of columns to drop\n",
    "columns_to_drop = ['segmentsAirlineName']\n",
    "df = df.select([col(column) for column in df.columns if column not in columns_to_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b1710d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('segmentsAirlineName_encoded', 'segmentsAirlineName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "267b3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4f3ae",
   "metadata": {},
   "source": [
    "# Predictive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b682610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33f154b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- elapsedDays: integer (nullable = true)\n",
      " |-- isBasicEconomy: boolean (nullable = true)\n",
      " |-- isNonStop: boolean (nullable = true)\n",
      " |-- totalFare: double (nullable = true)\n",
      " |-- seatsRemaining: integer (nullable = true)\n",
      " |-- totalTravelDistance: integer (nullable = true)\n",
      " |-- numberOfStops: integer (nullable = false)\n",
      " |-- travelDurationHour: integer (nullable = true)\n",
      " |-- travelDurationMinute: integer (nullable = true)\n",
      " |-- segmentsAirlineName: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5065ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ML Libraries and Preprocessing Tools\n",
    "from pyspark.ml.feature import VectorAssembler,MinMaxScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afc0cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and the target variable\n",
    "feature_columns = [\n",
    "    'elapsedDays',\n",
    "    'isBasicEconomy',\n",
    "    'isNonStop',\n",
    "    'seatsRemaining',\n",
    "    'totalTravelDistance',\n",
    "    'numberOfStops',\n",
    "    'travelDurationHour',\n",
    "    'travelDurationMinute',\n",
    "    'segmentsAirlineName'\n",
    "]\n",
    "\n",
    "target_column = 'totalFare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4105b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adaa740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MinMaxScaler\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08429025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "(training_data, testing_data) = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89cfaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=target_column, numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "705b4311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[scaler,rf])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9870a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "predictions = model.transform(testing_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=target_column, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489bae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=target_column)\n",
    "pipeline_dt = Pipeline(stages=[dt])\n",
    "model_dt = pipeline_dt.fit(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753192ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dt = model_dt.transform(testing_data)\n",
    "rmse_dt = evaluator.evaluate(predictions_dt)\n",
    "print(f\"Extra Trees Regressor - Root Mean Squared Error (RMSE): {rmse_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc34209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
